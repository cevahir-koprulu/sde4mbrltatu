{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, sampling_cfg, load_fn):\n",
    "    \"\"\" Load model sampler and time evolution function\n",
    "    \"\"\"\n",
    "    sampling_cfg = copy.deepcopy(sampling_cfg)\n",
    "    bae_model_fn, t_model = load_fn(model_name, \n",
    "                                modified_params = sampling_cfg, \n",
    "                                return_time_steps=True,\n",
    "                                return_control=True,)\n",
    "    return bae_model_fn, t_model\n",
    "\n",
    "\n",
    "def n_steps_analysis(xtraj, utraj, jit_sampling_fn, time_evol, data_stepsize, traj_time_evol):\n",
    "    \"\"\"Compute the time evolution of the mean and variance of the SDE at each time step\n",
    "\n",
    "    Args:\n",
    "        xtraj (TYPE): The trajectory of the states\n",
    "        utraj (TYPE): The trajectory of the inputs\n",
    "        jit_sampling_fn (TYPE): The sampling function return an array of size (num_particles, horizon, state_dim)\n",
    "        time_evol (TYPE): The time evolution of the sampling technique\n",
    "\n",
    "    Returns:\n",
    "        TYPE: The multi-sampled state evolution\n",
    "        TYPE: The time step evolution for plotting\n",
    "    \"\"\"\n",
    "    print(f\"time_evol: {time_evol}\")\n",
    "    print(f\"data_stepsize: {data_stepsize}\")\n",
    "    print(f\"traj_time_evol: {traj_time_evol}\")\n",
    "    sampler_horizon = len(time_evol) - 1\n",
    "    print(f\"sampler_horizon: {sampler_horizon}\")\n",
    "    dt_sampler = time_evol[1] - time_evol[0]\n",
    "\n",
    "    # Check if dt_sampler and data_stepsize are close enough\n",
    "    if abs(dt_sampler - data_stepsize) < 1e-5:\n",
    "        quot = 1\n",
    "    else:\n",
    "        assert dt_sampler > data_stepsize-1e-5, \"The time step of the sampling function must be larger than the data step size\"\n",
    "        assert abs(dt_sampler % data_stepsize) <= 1e-6, \"The time step of the sampling function must be a multiple of the data step size\"\n",
    "        quot = dt_sampler / data_stepsize\n",
    "    # print(time_evol)\n",
    "\n",
    "    # print(dt_sampler, data_stepsize, dt_sampler % sampler_horizon, sampler_horizon % dt_sampler)\n",
    "    # assert dt_sampler > data_stepsize-1e-6, \"The time step of the sampling function must be larger than the data step size\"\n",
    "    # assert abs(dt_sampler % data_stepsize) <= 1e-6, \"The time step of the sampling function must be a multiple of the data step size\"\n",
    "    quot = dt_sampler / data_stepsize\n",
    "    # Take the closest integer to quot\n",
    "    num_steps2data  = int(quot + 0.5)\n",
    "    # Compute the actual horizon for splitting the trajectories\n",
    "    traj_horizon = num_steps2data * sampler_horizon\n",
    "    utraj = utraj[:xtraj.shape[0]-1] # Remove the input rows if it is same or more than the state\n",
    "    # Split the trajectory into chunks of size num_steps2data\n",
    "    total_traj_size = (utraj.shape[0] // (traj_horizon)) * traj_horizon\n",
    "    # print('INFO: ', quot, num_steps2data, traj_horizon, total_traj_size, dt_sampler)\n",
    "    # print('INFO: ', xtraj.shape, utraj.shape, total_traj_size, traj_horizon, num_steps2data, sampler_horizon)\n",
    "\n",
    "    # print('INFO: ', quot, num_steps2data, traj_horizon, total_traj_size, dt_sampler)\n",
    "    # DOwngrade the xevol to its first 4 states\n",
    "    _xevol = xtraj[:total_traj_size+1]\n",
    "    _xevol_cut = _xevol[::num_steps2data]\n",
    "    _xevol_cut = np.array([_xevol_cut[i:i+sampler_horizon+1] for i in range(0, _xevol_cut.shape[0]-sampler_horizon, sampler_horizon)])\n",
    "    uevol = utraj[:total_traj_size]\n",
    "    uevol = uevol.reshape(-1, sampler_horizon, num_steps2data, uevol.shape[-1])\n",
    "    xevol = _xevol[::traj_horizon]\n",
    "    assert _xevol_cut.shape[0]+1 == xevol.shape[0], \"The number of trajectories must be the same for the states and inputs\"\n",
    "    # Reshape the time evolution\n",
    "    m_tevol = traj_time_evol[:total_traj_size+1][::traj_horizon]\n",
    "\n",
    "    # print('INFO: ', m_tevol.shape, xevol.shape, uevol.shape)\n",
    "    # assert xevol.shape[0] == uevol.shape[0], \"The number of trajectories must be the same for the states and inputs\"\n",
    "    # Initial random number generator\n",
    "    rng = jax.random.PRNGKey(20)\n",
    "    rng, s_rng = jax.random.split(rng)\n",
    "    xres = []\n",
    "    tres = []\n",
    "    err_analysis = []\n",
    "    for i in range(uevol.shape[0]):\n",
    "        rng, s_rng = jax.random.split(rng)\n",
    "        # _curr_u = np.mean(uevol[i], axis=-2)\n",
    "        _curr_u = uevol[i,:,0,:]\n",
    "        _curr_x = xevol[i]\n",
    "        _xpred, _ = jit_sampling_fn(_curr_x, _curr_u, s_rng) # (num_particles, horizon+1, state_dim)\n",
    "        _xpred = np.array(_xpred)\n",
    "        _tevol = m_tevol[i] + time_evol\n",
    "        # Let's compute the error with respect to the groundtruth\n",
    "        _mean_xevol = np.mean(_xpred, axis=0)\n",
    "        _error_xevol = np.abs(_mean_xevol - _xevol_cut[i])\n",
    "        _norm_xevol = np.linalg.norm(_error_xevol, axis=-1)\n",
    "        std_xevol = np.sum(np.std(_xpred, axis=0), axis=-1)\n",
    "        # COmpute the cumulative error\n",
    "        _cum_error_xevol = np.cumsum(_error_xevol, axis=0) / np.arange(1, _error_xevol.shape[0]+1)[:,None]\n",
    "        _cum_norm_xevol = np.cumsum(_norm_xevol, axis=0) / np.arange(1, _norm_xevol.shape[0]+1)\n",
    "        cum_std_xevol = np.cumsum(std_xevol, axis=0) / np.arange(1, std_xevol.shape[0]+1)\n",
    "        # COncatenate these 3 results\n",
    "        _res_analysis = np.concatenate([_cum_error_xevol, _cum_norm_xevol[:,None], cum_std_xevol[:,None], _tevol[:,None]], axis=-1)\n",
    "        if i < xevol.shape[0]-1:\n",
    "            _xpred = _xpred[:,:-1,:]\n",
    "            _tevol = _tevol[:-1]\n",
    "        xres.append(_xpred)\n",
    "        tres.append(_tevol)\n",
    "        err_analysis.append(_res_analysis)\n",
    "    # Merge the results along the horizon axis\n",
    "    xres = np.concatenate(xres, axis=1)\n",
    "    _tres = np.concatenate(tres, axis=0)\n",
    "    return xres, _tres, err_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "from models.tf_dynamics_models.bnn import BNN\n",
    "from models.tf_dynamics_models.constructor import construct_model\n",
    "\n",
    "import gym\n",
    "import d4rl\n",
    "\n",
    "def load_ensemble(load_dir, task='halfcheetah-random-v2', algo='tatu_mopo'):\n",
    "    model_dir = os.path.join('log', task, algo, load_dir, 'dynamics_model')\n",
    "    env = gym.make(task)\n",
    "    obs_shape = env.observation_space.shape\n",
    "    action_dim = np.prod(env.action_space.shape)\n",
    "    dynamics_model = construct_model(\n",
    "        obs_dim=np.prod(obs_shape),\n",
    "        act_dim=action_dim,\n",
    "        hidden_dim=200,\n",
    "        num_networks=7,\n",
    "        num_elites=5,\n",
    "        model_type=\"mlp\",\n",
    "        separate_mean_var=True,\n",
    "        load_dir=model_dir,\n",
    "        name=\"BNN_0\",\n",
    "    )\n",
    "    return dynamics_model\n",
    "\n",
    "def predict_with_ensemble(dynamics_model, num_traj=1, deterministic=False):\n",
    "    def ensemble_sampling_fn(x, us):\n",
    "        x = np.ones((num_traj,x.shape[0]))*x \n",
    "        xs = [x]\n",
    "        stds = [np.zeros_like(x)]        \n",
    "        for u in us:\n",
    "            u_ = np.ones((num_traj, u.shape[0])) * u\n",
    "            inputs = np.concatenate((x, u_), axis=-1)\n",
    "            ens_model_means, ens_model_vars = dynamics_model.predict(inputs, factored=True)\n",
    "            ens_model_means = ens_model_means[:,:,1:] + x # Remove reward and move\n",
    "            ens_model_stds = np.sqrt(ens_model_vars[:,:,1:])\n",
    "            if deterministic:\n",
    "                ens_samples = ens_model_means\n",
    "                samples = np.mean(ens_samples, axis=0)\n",
    "                model_means = np.mean(ens_model_means, axis=0)\n",
    "                model_stds = np.mean(ens_model_stds, axis=0)\n",
    "            else:\n",
    "                ens_samples = ens_model_means + np.random.normal(size=ens_model_means.shape) * ens_model_stds\n",
    "                #### choose one model from ensemble\n",
    "                num_models = ens_model_means.shape[0]\n",
    "                model_inds = np.random.choice(num_models, size=num_traj)\n",
    "                samples = np.array([ens_samples[model_ind,i,:] for i, model_ind in enumerate(model_inds)])\n",
    "                model_means = np.array([ens_model_means[model_ind,i,:] for i, model_ind in enumerate(model_inds)])\n",
    "                model_stds = np.array([ens_model_stds[model_ind,i,:] for i, model_ind in enumerate(model_inds)])\n",
    "            x = samples\n",
    "            xs.append(x)\n",
    "            stds.append(model_stds)\n",
    "        return np.array(xs).transpose(1,0,2), np.array(stds).transpose(1,0,2)\n",
    "    return ensemble_sampling_fn\n",
    "\n",
    "def n_steps_analysis_ensemble(xtraj, utraj, ensemble_sampling_fn, time_evol, data_stepsize, traj_time_evol):\n",
    "    \"\"\"Compute the time evolution of the mean and variance of the SDE at each time step\n",
    "\n",
    "    Args:\n",
    "        xtraj (TYPE): The trajectory of the states\n",
    "        utraj (TYPE): The trajectory of the inputs\n",
    "        jit_sampling_fn (TYPE): The sampling function return an array of size (num_particles, horizon, state_dim)\n",
    "        time_evol (TYPE): The time evolution of the sampling technique\n",
    "\n",
    "    Returns:\n",
    "        TYPE: The multi-sampled state evolution\n",
    "        TYPE: The time step evolution for plotting\n",
    "    \"\"\"\n",
    "    sampler_horizon = len(time_evol) - 1\n",
    "    dt_sampler = time_evol[1] - time_evol[0]\n",
    "\n",
    "    # Check if dt_sampler and data_stepsize are close enough\n",
    "    if abs(dt_sampler - data_stepsize) < 1e-5:\n",
    "        quot = 1\n",
    "    else:\n",
    "        assert dt_sampler > data_stepsize-1e-5, \"The time step of the sampling function must be larger than the data step size\"\n",
    "        assert abs(dt_sampler % data_stepsize) <= 1e-6, \"The time step of the sampling function must be a multiple of the data step size\"\n",
    "        quot = dt_sampler / data_stepsize\n",
    "\n",
    "    quot = dt_sampler / data_stepsize\n",
    "    # Take the closest integer to quot\n",
    "    num_steps2data  = int(quot + 0.5)\n",
    "    # Compute the actual horizon for splitting the trajectories\n",
    "    traj_horizon = num_steps2data * sampler_horizon\n",
    "    utraj = utraj[:xtraj.shape[0]-1] # Remove the input rows if it is same or more than the state\n",
    "    # Split the trajectory into chunks of size num_steps2data\n",
    "    total_traj_size = (utraj.shape[0] // (traj_horizon)) * traj_horizon\n",
    "\n",
    "    # DOwngrade the xevol to its first 4 states\n",
    "    _xevol = xtraj[:total_traj_size+1]\n",
    "    _xevol_cut = _xevol[::num_steps2data]\n",
    "    _xevol_cut = np.array([_xevol_cut[i:i+sampler_horizon+1] for i in range(0, _xevol_cut.shape[0]-sampler_horizon, sampler_horizon)])\n",
    "    uevol = utraj[:total_traj_size]\n",
    "    uevol = uevol.reshape(-1, sampler_horizon, num_steps2data, uevol.shape[-1])\n",
    "    xevol = _xevol[::traj_horizon]\n",
    "    # print(xevol.shape, _xevol_cut.shape)\n",
    "    assert _xevol_cut.shape[0]+1 == xevol.shape[0], \"The number of trajectories must be the same for the states and inputs\"\n",
    "    # Reshape the time evolution\n",
    "    m_tevol = traj_time_evol[:total_traj_size+1][::traj_horizon]\n",
    "\n",
    "    # Initial random number generator\n",
    "    rng = jax.random.PRNGKey(20)\n",
    "    rng, s_rng = jax.random.split(rng)\n",
    "    xres = []\n",
    "    tres = []\n",
    "    err_analysis = []\n",
    "    for i in range(uevol.shape[0]):\n",
    "        rng, s_rng = jax.random.split(rng)\n",
    "        _curr_u = uevol[i,:,0,:]\n",
    "        _curr_x = xevol[i]\n",
    "        _xpred, _xstd = ensemble_sampling_fn(_curr_x, _curr_u) # (num_particles, horizon+1, state_dim)\n",
    "        _tevol = m_tevol[i] + time_evol\n",
    "        # Let's compute the error with respect to the groundtruth\n",
    "        # _error_xevol = np.abs(_xpred[0] - _xevol_cut[i])\n",
    "        # _norm_xevol = np.linalg.norm(_error_xevol, axis=-1)\n",
    "        # std_xevol = np.sum(_xstd[0], axis=-1)\n",
    "        \n",
    "        _mean_xevol = np.mean(_xpred, axis=0)\n",
    "        _error_xevol = np.abs(_mean_xevol - _xevol_cut[i])\n",
    "        _norm_xevol = np.linalg.norm(_error_xevol, axis=-1)\n",
    "        std_xevol = np.sum(np.std(_xpred, axis=0), axis=-1)\n",
    "        \n",
    "        # COmpute the cumulative error\n",
    "        _cum_error_xevol = np.cumsum(_error_xevol, axis=0) / np.arange(1, _error_xevol.shape[0]+1)[:,None]\n",
    "        _cum_norm_xevol = np.cumsum(_norm_xevol, axis=0) / np.arange(1, _norm_xevol.shape[0]+1)\n",
    "        cum_std_xevol = np.cumsum(std_xevol, axis=0) / np.arange(1, std_xevol.shape[0]+1)\n",
    "        # COncatenate these 3 results\n",
    "        _res_analysis = np.concatenate([_cum_error_xevol, _cum_norm_xevol[:,None], cum_std_xevol[:,None], _tevol[:,None]], axis=-1)\n",
    "        if i < xevol.shape[0]-1:\n",
    "            _xpred = _xpred[:,:-1,:]\n",
    "            _tevol = _tevol[:-1]\n",
    "        xres.append(_xpred)\n",
    "        tres.append(_tevol)\n",
    "        err_analysis.append(_res_analysis)\n",
    "    # Merge the results along the horizon axis\n",
    "    xres = np.concatenate(xres, axis=1)\n",
    "    _tres = np.concatenate(tres, axis=0)\n",
    "    return xres, _tres, err_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_trajectory(task, initial_obs, actions):\n",
    "    env = gym.make(task)\n",
    "    env.reset()\n",
    "    qpos = np.concatenate(([env.data.qpos.flatten()[0]], initial_obs[:8]))\n",
    "    qvel = initial_obs[8:]\n",
    "    env.set_state(qpos, qvel)\n",
    "    obs = initial_obs\n",
    "    obs_list = [obs]\n",
    "    for act in actions:\n",
    "        obs, _, _, _ = env.step(act)\n",
    "        obs_list.append(obs)\n",
    "    return np.array(obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_model(dataset, model_names, ensemble_model_name, hr, num_extra_steps, num_sample, \n",
    "                  num_traj = 1, use_train=False, seed=10, plot_xevol=False, plot_gt_env_in_chunks=True, deterministic_ensemble=False):\n",
    "    \"\"\" Do the analysis of some of the existing models\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    # current_dir = os.path.expanduser(os.path.dirname(os.path.abspath(__file__)))\n",
    "    current_dir = os.getcwd()\n",
    "    data_dir = current_dir + '/models/sde_models/training_dataset/' + dataset + '_dataset.pkl'\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise ValueError(\"The dataset {} does not exist\".format(data_dir))\n",
    "    # Open the file and load the data\n",
    "    with open(data_dir, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Extract the data\n",
    "    data = data['test_data'] if not use_train else data['train_data']\n",
    "\n",
    "    # Print the number of trajectories\n",
    "    print(\"Number of trajectories: {}\".format(len(data)))\n",
    "    lentraj = [s['y'].shape[0] for s in data]\n",
    "    # print ('Total number of datapoints: ', sum(lentraj))\n",
    "    # print('Number of datapints per trajectories: ', lentraj)\n",
    "\n",
    "    # Pick randomly a trajectory\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Load the model, predictor function and useful constants for plotting\n",
    "    if 'halfcheetah' in dataset:\n",
    "        from models.sde_models.halfcheetah_sde import load_predictor_function, OBS_NAMES, CONTROL_NAMES, TIMESTEP_ENV\n",
    "    elif 'hopper' in dataset:\n",
    "        from models.sde_models.hopper_sde import load_predictor_function, OBS_NAMES, CONTROL_NAMES, TIMESTEP_ENV\n",
    "    elif 'walker' in dataset:\n",
    "        from models.sde_models.walker_sde import load_predictor_function, OBS_NAMES, CONTROL_NAMES, TIMESTEP_ENV\n",
    "    else:\n",
    "        raise ValueError(\"The dataset {} is not supported\".format(dataset))\n",
    "\n",
    "    # We need to eliminate the trajectories that are too short according to the horizon and the number of extra steps\n",
    "    valid_idx_traj = np.array([ _i for _i, _len in enumerate(lentraj) if _len >= num_extra_steps*hr])\n",
    "    traj_idx = np.random.choice(len(valid_idx_traj), size=num_traj, replace=False) # Get the index of a random trajectory\n",
    "    print(f\"TRAJ_ID: {traj_idx} || IS_TRAIN: {use_train}\")\n",
    "    traj_idx = valid_idx_traj[traj_idx] # Get the actual index of the trajectory\n",
    "    curr_traj_y_list, curr_traj_u_list = [], []\n",
    "    for _idx in traj_idx:\n",
    "        curr_traj_y_list.append(np.concatenate((data[_idx]['y'], data[_idx]['y'][-1:]), axis=0))\n",
    "        curr_traj_u_list.append(data[_idx]['u'][:curr_traj_y_list[-1].shape[0]])\n",
    "\n",
    "    # curr_traj_y = np.concatenate((data[traj_idx]['y'], data[traj_idx]['y'][-1:]), axis=0)\n",
    "    # curr_traj_u = data[traj_idx]['u'][:curr_traj_y.shape[0]]\n",
    "\n",
    "    # Time evolution of the trajectory\n",
    "    # traj_time_evol = np.array([TIMESTEP_ENV * i for i in range(curr_traj_y_list[-1].shape[0])])\n",
    "        \n",
    "    gt_env_y_list = []\n",
    "    for curr_traj_y, curr_traj_u in zip(curr_traj_y_list, curr_traj_u_list):\n",
    "        if plot_gt_env_in_chunks:\n",
    "            chunks = []\n",
    "            for num_chunk in range(curr_traj_y.shape[0]//hr):\n",
    "                curr_traj_y_init = curr_traj_y[num_chunk*hr]\n",
    "                gt_chunk = get_gt_trajectory(dataset, curr_traj_y[num_chunk*hr], curr_traj_u[num_chunk*hr:num_chunk*hr+hr-1])\n",
    "                chunks.append(gt_chunk)\n",
    "            chunks.append([curr_traj_y[(curr_traj_y.shape[0]//hr)*hr]])\n",
    "            gt_env_y_list.append(np.concatenate(chunks, axis=0))\n",
    "            print(f\"gt_env_y_list: {gt_env_y_list[0].shape}\")\n",
    "        else:\n",
    "            curr_traj_y_init = curr_traj_y[0]\n",
    "            gt_env_y_list.append(get_gt_trajectory(dataset, curr_traj_y_init, curr_traj_u))\n",
    "\n",
    "    curr_traj_time_list = [np.array([TIMESTEP_ENV * i for i in range(_y.shape[0])]) for _y in curr_traj_y_list]\n",
    "\n",
    "    # Names of the states and controls\n",
    "    state_names = OBS_NAMES\n",
    "    control_names = CONTROL_NAMES\n",
    "\n",
    "    # We do a two column plot\n",
    "    num_states = len(state_names)\n",
    "    num_controls = len(control_names)\n",
    "\n",
    "    # maximum plots per column\n",
    "    MAX_PLOTS_PER_COL = 5\n",
    "    PER_CELL_FIG_SIZE = (4, 4)\n",
    "\n",
    "    # number of rows and columns\n",
    "    total_axis = num_states + num_controls\n",
    "    num_cols = min(MAX_PLOTS_PER_COL, total_axis)\n",
    "    num_rows = (total_axis // num_cols) + (1 if total_axis % num_cols != 0 else 0)\n",
    "    TOTAL_FIG_SIZE = (num_cols * PER_CELL_FIG_SIZE[0], num_rows * PER_CELL_FIG_SIZE[1])\n",
    "\n",
    "    # Define the figures\n",
    "    fig_state, fig_err, fig_tot_err = None, None, None\n",
    "    # Pick the colors\n",
    "    gt_color = '#000000'\n",
    "    # Pick color for each model -> LImited number to plot\n",
    "    model_colors = ['#ff0000', '#00ff00', '#0000ff', '#ff00ff', '#00ffff']\n",
    "    line_width = 2\n",
    "\n",
    "    # Load ensemble\n",
    "    ensemble_dynamics = load_ensemble(load_dir=ensemble_model_name, task=dataset, algo='tatu_mopo')\n",
    "    ensemble_sampling_fn = predict_with_ensemble(ensemble_dynamics, num_traj=num_sample, deterministic=deterministic_ensemble)\n",
    "            \n",
    "    # Iterate through the models\n",
    "    print('INFO: Analyzing the following models: ', model_names)\n",
    "    for model_idx, model_name in enumerate(model_names):\n",
    "\n",
    "        # Define up the sampling configuration\n",
    "        sampling_cfg = {\n",
    "            'num_particles' : num_sample,\n",
    "            'horizon' : hr,\n",
    "            'stepsize' : num_extra_steps * TIMESTEP_ENV,\n",
    "        }\n",
    "\n",
    "        # Load the model, the predictor function, and perform the analysis\n",
    "        model_fn, t_model = create_model(model_name, sampling_cfg, load_predictor_function)\n",
    "        base_model_fn_jit = jax.jit(model_fn)\n",
    "        err_res = []\n",
    "        for curr_traj_y, curr_traj_u, traj_time_evol in zip(curr_traj_y_list, curr_traj_u_list, curr_traj_time_list):\n",
    "            _xres, _tres, _err_res = n_steps_analysis(curr_traj_y, curr_traj_u, base_model_fn_jit, t_model, TIMESTEP_ENV, traj_time_evol)\n",
    "            err_res.extend(_err_res)\n",
    "        \n",
    "        if model_idx == 0:\n",
    "            err_res_ensemble = []\n",
    "            for curr_traj_y, curr_traj_u, traj_time_evol in zip(curr_traj_y_list, curr_traj_u_list, curr_traj_time_list):\n",
    "                _xres_ensemble, _tres_ensemble, _err_res_ensemble = n_steps_analysis_ensemble(curr_traj_y, curr_traj_u, ensemble_sampling_fn, t_model, TIMESTEP_ENV, traj_time_evol)\n",
    "                err_res_ensemble.extend(_err_res_ensemble)\n",
    "\n",
    "        curr_color = model_colors[model_idx]\n",
    "        _model_name = model_name.split('_sde.pkl')[0] if '_sde.pkl' in model_name else model_name\n",
    "\n",
    "        # # Figures to plot the results\n",
    "        if plot_xevol:\n",
    "            if fig_state is None:\n",
    "                fig_state, axs_state = plt.subplots(num_rows, num_cols, figsize=TOTAL_FIG_SIZE, sharex=True)\n",
    "                axs_state = axs_state.flatten()\n",
    "\n",
    "            axs = axs_state\n",
    "            for i in range(num_states):\n",
    "\n",
    "                # Plot the ground truth & ground truth env\n",
    "                if model_idx == 0:\n",
    "                    axs[i].plot(traj_time_evol, curr_traj_y[:,i], color=gt_color, label='Ground truth', linewidth=line_width)\n",
    "                    axs[i].plot(traj_time_evol, gt_env_y_list[0][:,i], color='magenta', label='Ground truth Env', linewidth=line_width)\n",
    "                    axs[i].scatter(traj_time_evol[::hr], curr_traj_y[::hr,i], color=gt_color, marker='x')\n",
    "                    for k in range(_xres_ensemble.shape[0]):\n",
    "                        axs[i].plot(_tres_ensemble, _xres_ensemble[k,:,i], color='green', label='ensemble' if k == 0 else None)            \n",
    "\n",
    "                \n",
    "                # Extract the current color and model name\n",
    "                curr_color = model_colors[model_idx]\n",
    "                _model_name = model_name.split('_sde.pkl')[0] if '_sde.pkl' in model_name else model_name\n",
    "                # print('Xres: ', _xres.shape, _xres.shape)\n",
    "\n",
    "                # Plot the results for the current model\n",
    "                for k in range(_xres.shape[0]):\n",
    "                    axs[i].plot(_tres, _xres[k,:,i], color=curr_color, label=_model_name if k == 0 else None)            \n",
    "            \n",
    "                # Set the labels\n",
    "                if model_idx == len(model_names)-1:\n",
    "                    axs[i].set_xlabel('Time (s)')\n",
    "                    axs[i].set_ylabel(state_names[i])\n",
    "                    axs[i].grid(True)\n",
    "                    if i == 0:\n",
    "                        axs[i].legend()\n",
    "\n",
    "            # Plot the controls\n",
    "            if model_idx == 0:\n",
    "                for i in range(num_controls):\n",
    "                    axs[i + num_states].plot(traj_time_evol[:-1], curr_traj_u[:,i], color=gt_color, label='Ground truth')\n",
    "                    axs[i + num_states].set_xlabel('Time (s)')\n",
    "                    axs[i + num_states].set_ylabel(control_names[i])\n",
    "                    axs[i + num_states].grid(True)\n",
    "        \n",
    "        # Now ler's plot the average error over the prediction horizon for each state\n",
    "        _error_full = err_res\n",
    "        _err_array = _error_full[0]\n",
    "        full_state_error = np.array([_v[:,:num_states] for _v in _error_full])\n",
    "        # metric_fn = getattr(np, metric_fun)\n",
    "        # full_state_error = metric_fn(full_state_error, axis=0)\n",
    "        full_state_error_mean = np.mean(full_state_error, axis=0)\n",
    "        full_state_error_min = np.min(full_state_error, axis=0)\n",
    "        full_state_error_max = np.max(full_state_error, axis=0)\n",
    "                \n",
    "        _error_full_ensemble = err_res_ensemble\n",
    "        _err_array_ensemble = _error_full_ensemble[0]\n",
    "        full_state_error_ensemble = np.array([_v[:,:num_states] for _v in _error_full_ensemble])\n",
    "        full_state_error_mean_ensemble = np.mean(full_state_error_ensemble, axis=0)\n",
    "        full_state_error_min_ensemble = np.min(full_state_error_ensemble, axis=0)\n",
    "        full_state_error_max_ensemble = np.max(full_state_error_ensemble, axis=0)\n",
    "        \n",
    "\n",
    "        if fig_err is None:\n",
    "            fig_err, axs_err = [], []\n",
    "            for _i in range(1):\n",
    "                _fig, _axs = plt.subplots(num_rows,num_cols,figsize=TOTAL_FIG_SIZE,sharex=True)\n",
    "                _axs = _axs.flatten()\n",
    "                fig_err.append(_fig)\n",
    "                axs_err.append(_axs)\n",
    "        \n",
    "        # for _fig, _axs in zip(fig_err, axs_err):\n",
    "        _fig, axs = fig_err[0], axs_err[0]\n",
    "        for i in range(num_states):\n",
    "            state_error = full_state_error_mean[:,i]\n",
    "            axs[i].plot(_err_array[:,-1], state_error, color=curr_color, label=_model_name)\n",
    "            axs[i].fill_between(_err_array[:,-1], full_state_error_min[:,i], full_state_error_max[:,i], facecolor=curr_color, alpha=0.25, edgecolor='k')\n",
    "            axs[i].plot(_err_array_ensemble[:,-1], full_state_error_mean_ensemble[:,i], color='green', label='ensemble')\n",
    "            axs[i].fill_between(_err_array_ensemble[:,-1], full_state_error_min_ensemble[:,i], full_state_error_max_ensemble[:,i], facecolor='green', alpha=0.25, edgecolor='k')\n",
    "            if model_idx == len(model_names)-1:\n",
    "                axs[i].set_xlabel('Time (s)')\n",
    "                axs[i].set_ylabel('Error in ' + state_names[i])\n",
    "                axs[i].grid(True)\n",
    "                if i == 0:\n",
    "                    axs[i].legend()\n",
    "\n",
    "        # Now let's plot the total error in norm and standard deviation\n",
    "        norm_error = np.array([_v[:,num_states] for _v in _error_full])\n",
    "        norm_error_mean = np.mean(norm_error, axis=0)\n",
    "        norm_error_min = np.min(norm_error, axis=0)\n",
    "        norm_error_max = np.max(norm_error, axis=0)\n",
    "\n",
    "        norm_error_ensemble = np.array([_v[:,num_states] for _v in _error_full_ensemble])\n",
    "        norm_error_mean_ensemble = np.mean(norm_error_ensemble, axis=0)\n",
    "        norm_error_min_ensemble = np.min(norm_error_ensemble, axis=0)\n",
    "        norm_error_max_ensemble = np.max(norm_error_ensemble, axis=0)\n",
    "\n",
    "        # norm_error = metric_fn(norm_error, axis=0)\n",
    "\n",
    "        if fig_tot_err is None:\n",
    "            fig_tot_err, axs_tot_err = plt.subplots(1,2,figsize=(10,5),sharex=True)\n",
    "            axs_tot_err = axs_tot_err.flatten()\n",
    "\n",
    "        # Now we show the norm and standard deviation of the error\n",
    "        # _err_array = _error_full[0]\n",
    "        axs_tot_err[0].plot(_err_array[:,-1], norm_error_mean, color=curr_color, label=_model_name)\n",
    "        axs_tot_err[0].fill_between(_err_array[:,-1], norm_error_min, norm_error_max, facecolor=curr_color, alpha=0.25, edgecolor='k')\n",
    "        axs_tot_err[0].plot(_err_array_ensemble[:,-1], norm_error_mean_ensemble, color='green', label='ensemble')\n",
    "        axs_tot_err[0].fill_between(_err_array_ensemble[:,-1], norm_error_min_ensemble, norm_error_max_ensemble, facecolor='green', alpha=0.25, edgecolor='k')\n",
    "        axs_tot_err[0].set_xlabel('Time (s)')\n",
    "        axs_tot_err[0].set_ylabel('Norm of the error')\n",
    "        axs_tot_err[0].grid(True)\n",
    "\n",
    "        std_error = np.array([_v[:,num_states+1] for _v in _error_full])\n",
    "        std_error_mean = np.mean(std_error, axis=0)\n",
    "        std_error_min = np.min(std_error, axis=0)\n",
    "        std_error_max = np.max(std_error, axis=0)\n",
    "        std_error_ensemble = np.array([_v[:,num_states+1] for _v in _error_full_ensemble])\n",
    "        std_error_mean_ensemble = np.mean(std_error_ensemble, axis=0)\n",
    "        std_error_min_ensemble = np.min(std_error_ensemble, axis=0)\n",
    "        std_error_max_ensemble = np.max(std_error_ensemble, axis=0)\n",
    "        # Now we show the norm and standard deviation of the error\n",
    "        axs_tot_err[1].plot(_err_array[:,-1], std_error_mean, color=curr_color, label=_model_name)\n",
    "        axs_tot_err[1].fill_between(_err_array[:,-1], std_error_min, std_error_max, facecolor=curr_color, alpha=0.25)\n",
    "        axs_tot_err[1].plot(_err_array_ensemble[:,-1], std_error_mean_ensemble, color='green', label='ensemble')\n",
    "        axs_tot_err[1].fill_between(_err_array_ensemble[:,-1], std_error_min_ensemble, std_error_max_ensemble, facecolor='green', alpha=0.25)\n",
    "        axs_tot_err[1].set_xlabel('Time (s)')\n",
    "        axs_tot_err[1].set_ylabel('Standard deviation of the error')\n",
    "        axs_tot_err[1].grid(True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = 'hopper-random-v2'\n",
    "# model_names = ['random_hop_hr-20_dt-0.002_sde.pkl',]\n",
    "# ensemble_model = 'critic_num_2_seed_32_0109_104839-hopper_medium_v2_tatu_mopo'\n",
    "\n",
    "dataset = 'halfcheetah-random-v2'\n",
    "model_names = ['random_hc_vf4_hr-10_dt-0.010_sde.pkl',]\n",
    "ensemble_model = 'critic_num_2_seed_32_0303_125950-halfcheetah_random_v2_tatu_mopo'\n",
    "\n",
    "# dataset = 'walker2d-random-v2'\n",
    "# model_names = ['random_walker_v1_hr-20_dt-0.002_sde.pkl',]\n",
    "\n",
    "hr = 50\n",
    "num_extra_steps = 1\n",
    "num_sample = 5\n",
    "num_traj = 1\n",
    "use_train = False\n",
    "seed = 9\n",
    "plot_xevol = True\n",
    "plot_gt_env_in_chunks = True\n",
    "deterministic_ensemble = True\n",
    "analyze_model(dataset, model_names, ensemble_model, hr, num_extra_steps, num_sample, num_traj, use_train, seed, plot_xevol, plot_gt_env_in_chunks, deterministic_ensemble)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sde4mbrltatu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
