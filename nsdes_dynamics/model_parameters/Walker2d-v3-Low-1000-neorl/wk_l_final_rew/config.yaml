dad_optimizer:
- name: scale_by_adam
- name: linear_schedule
  params:
    end_value: -0.001
    init_value: -0.001
    transition_steps: 100000
  scheduler: true
dataset:
  name: Walker2d-v3-Low-1000-neorl
  normalize_data: true
  seed: 10
  test_ratio: 0.2
env_name: Walker2d-v3-Low-1000-neorl
extra_infos:
  is_diff_distance_aware: true
  max_fields:
    Abfoot: 1.8618978261947632
    Abshin: 4.716975688934326
    Abthigh: 3.8385610580444336
    Affoot: 2.1812212467193604
    Afshin: 3.1249325275421143
    Afthigh: 3.179900884628296
    Arooty: 4.387390613555908
    Cbfoot: 7.2242865562438965
    Cbshin: 9.182477951049805
    Cbthigh: 14.398853302001953
    Cffoot: 7.473564147949219
    Cfshin: 9.122353553771973
    Cfthigh: 8.425827980041504
    Vrootx: 5.894685745239258
    Vrootz: 5.600703716278076
    bfoot: 3.532050609588623
    bshin: 19.56358528137207
    bthigh: 20.477123260498047
    ffoot: 2.92687726020813
    fshin: 12.386795997619629
    fthigh: 6.758758068084717
    reward: 4.2495078969631495
    rootx: 4.911701202392578
    rooty: 5.7479023933410645
    rootz: 4.308528423309326
  names_controls:
  - Cbthigh
  - Cbshin
  - Cbfoot
  - Cfthigh
  - Cfshin
  - Cffoot
  names_positions:
  - rootx
  - rootz
  - rooty
  - bthigh
  - bshin
  - bfoot
  - fthigh
  - fshin
  - ffoot
  names_states:
  - rootx
  - rootz
  - rooty
  - bthigh
  - bshin
  - bfoot
  - fthigh
  - fshin
  - ffoot
  - Vrootx
  - Vrootz
  - Arooty
  - Abthigh
  - Abshin
  - Abfoot
  - Afthigh
  - Afshin
  - Affoot
  - reward
loss_definitions:
  loss_diffusion:
    cvx_coeff_config:
      cvx_coeff_params:
        coef_init: 100.0
        is_constant: true
      is_cvx_coeff_learned: true
    diff_loss_config:
      ball_num_samples: 20
      ball_radius: 0.1
      cvx_coeff_loss_type: quad_inv
      min_grad_density: 1.0e-06
      weight_diff_loss:
        cvx_coeff_loss: 1
        density_set_one: 0.0001
        density_value: 0.001
        gradient_loss: 1.0e-05
        local_convex_loss: 1
      weight_min_grad_density: 1000.0
  loss_reg:
    default_mean: 0
    default_scale: 0
    specials:
      actuator_forces:
        mean: 0.0
        scale: 1
      coriolis_forces:
        mean: 0.0
        scale: 1
      gravity_forces:
        mean: 0.0
        scale: 1
      position_correction:
        mean: 0.0
        scale: 1
      residual_forces:
        mean: 0.0
        scale: 1
  loss_traj_train:
    discount_factor: 0.9
    likehood:
      discount_factor: 0.9
      nll_type: gauss_approx
      noise_scale:
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
    num_substeps: 1
    sampling:
      action_sampling_strategy:
        default: first
      horizon_fit: 2
      integration_method: euler_maruyama
      num_samples: 1
      stepsize_range:
      - 1
      - 1
    validation_sampling:
      action_sampling_strategy:
        default: first
      horizon_test: 5
      stepsize_range:
      - 1
      - 1
  loss_weights:
    DataLoss: 1.0
    RegLoss: 0.0005
    VarBoundLoss: 0.001
model:
  diffusion_term:
    args:
      _num_controls: 6
      _num_states: 19
      default_feature_values: []
      density_free_nn_params:
        activation_fn: swish
        initial_value_range: 0.001
        layers_archictecture: []
      density_nn_params:
        activation_fn: swish
        initial_value_range: 0.1
        layers_archictecture:
        - 64
        - 64
      diffusion_is_control_dependent: true
      feature_density_scaling:
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      feature_parameters_to_use: []
      is_reward_in_state: true
      upper_bound_diffusion:
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0
    model_name: BasicDistanceAwareDiffusionTerm
  drift_term:
    args:
      _mean_controls:
      - 0.5069929957389832
      - 0.5121824145317078
      - 0.2327987551689148
      - 0.02303316444158554
      - 0.3351302742958069
      - -0.49399977922439575
      _mean_states:
      - 2.3912761211395264
      - 1.2633898258209229
      - 0.21088050305843353
      - -0.0070510199293494225
      - 0.00025419832672923803
      - 0.48392629623413086
      - -0.24043530225753784
      - -0.043262336403131485
      - -0.45104342699050903
      - 1.3362571001052856
      - -0.093234121799469
      - 0.19646520912647247
      - -0.01996852643787861
      - -0.032174002379179
      - -0.630435049533844
      - -0.013519098050892353
      - -0.16141822934150696
      - 0.010558458976447582
      - 588.8118505409071
      _names_angles:
      - rooty
      - bthigh
      - bshin
      - bfoot
      - fthigh
      - fshin
      - ffoot
      _names_controls:
      - Cbthigh
      - Cbshin
      - Cbfoot
      - Cfthigh
      - Cfshin
      - Cffoot
      _names_positions:
      - rootx
      - rootz
      - rooty
      - bthigh
      - bshin
      - bfoot
      - fthigh
      - fshin
      - ffoot
      _names_states:
      - rootx
      - rootz
      - rooty
      - bthigh
      - bshin
      - bfoot
      - fthigh
      - fshin
      - ffoot
      - Vrootx
      - Vrootz
      - Arooty
      - Abthigh
      - Abshin
      - Abfoot
      - Afthigh
      - Afshin
      - Affoot
      - reward
      _scale_controls:
      - 0.6647294163703918
      - 0.5525546073913574
      - 0.7840228080749512
      - 0.6468552350997925
      - 0.5545883178710938
      - 0.7363891005516052
      _scale_states:
      - 2.01436448097229
      - 0.10753794014453888
      - 0.21042583882808685
      - 0.06263983994722366
      - 0.05134902521967888
      - 0.5855917930603027
      - 0.20071470737457275
      - 0.14386974275112152
      - 0.6526742577552795
      - 0.8451191782951355
      - 0.8835218548774719
      - 2.3240387439727783
      - 2.6103451251983643
      - 2.1268234252929688
      - 5.7094621658325195
      - 3.149003505706787
      - 3.2517240047454834
      - 4.589427947998047
      - 434.2568917648362
      actuator_forces_nn:
        args:
          activation_fn: swish
          initial_value_range: 0.001
          layers_archictecture:
          - 128
          - 128
          - 128
        features:
        - rootz
        - cos_angles
        - sin_angles
        - velocities
      coriolis_forces_nn:
        args:
          activation_fn: swish
          initial_value_range: 0.001
          layers_archictecture:
          - 128
          - 128
          - 128
        features:
        - rootz
        - cos_angles
        - sin_angles
        - velocities
      gravity_forces_nn: {}
      mass_matrix_nn: {}
      residual_forces_nn:
        args:
          activation_fn: swish
          initial_value_range: 0.001
          layers_archictecture:
          - 200
          - 200
          - 200
        features:
        - rootz
        - cos_angles
        - sin_angles
        - velocities
        - controls
      reward_nn:
        args:
          activation_fn: swish
          initial_value_range: 0.001
          layers_archictecture:
          - 64
          - 64
          - 64
        features:
        - positions
        - velocities
        - controls
    model_name: RBD_Drift
model_optimizer:
- name: scale_by_adam
- name: linear_schedule
  params:
    end_value: -0.001
    init_value: -0.01
    transition_steps: 100000
  scheduler: true
model_training:
  dad_batch_size: 128
  early_stopping_epochs: 300
  freq_update_dad: 1
  num_gradient_steps: 400
  save_freq: 4000
  test_batch: 128
  test_freq: 2000
  test_num_steps: 80
  train_batch: 128
seed: 100
track_n_checkpoints:
  async_exec: false
  max_to_keep: 5
  metrics:
    Test/StateLoss: 5.0
    Train/StateLoss: 1.0
