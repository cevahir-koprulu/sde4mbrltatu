dad_optimizer:
- name: scale_by_adam
- name: linear_schedule
  params:
    end_value: -0.001
    init_value: -0.001
    transition_steps: 100000
  scheduler: true
dataset:
  name: HalfCheetah-v3-Medium-1000-neorl
  normalize_data: true
  seed: 10
  test_ratio: 0.2
env_name: HalfCheetah-v3-Medium-1000-neorl
extra_infos:
  is_diff_distance_aware: true
  max_fields:
    Abfoot: 3.1017651557922363
    Abshin: 3.6559877395629883
    Abthigh: 2.397061347961426
    Affoot: 3.2389514446258545
    Afshin: 2.794536590576172
    Afthigh: 4.132153511047363
    Arooty: 4.432114124298096
    Cbfoot: 4.677573204040527
    Cbshin: 4.9175567626953125
    Cbthigh: 5.071827411651611
    Cffoot: 4.355489253997803
    Cfshin: 4.5808491706848145
    Cfthigh: 5.003737449645996
    Vrootx: 5.3275465965271
    Vrootz: 5.4229736328125
    bfoot: 2.5720815658569336
    bshin: 2.8276283740997314
    bthigh: 2.3164334297180176
    ffoot: 2.20595645904541
    fshin: 2.6774895191192627
    fthigh: 4.523101806640625
    reward: 1.8642832638655598
    rootx: 1.871211290359497
    rooty: 12.196128845214844
    rootz: 9.477628707885742
  names_controls:
  - Cbthigh
  - Cbshin
  - Cbfoot
  - Cfthigh
  - Cfshin
  - Cffoot
  names_positions:
  - rootx
  - rootz
  - rooty
  - bthigh
  - bshin
  - bfoot
  - fthigh
  - fshin
  - ffoot
  names_states:
  - rootx
  - rootz
  - rooty
  - bthigh
  - bshin
  - bfoot
  - fthigh
  - fshin
  - ffoot
  - Vrootx
  - Vrootz
  - Arooty
  - Abthigh
  - Abshin
  - Abfoot
  - Afthigh
  - Afshin
  - Affoot
  - reward
loss_definitions:
  loss_diffusion:
    cvx_coeff_config:
      cvx_coeff_params:
        coef_init: 100.0
        is_constant: true
      is_cvx_coeff_learned: true
    diff_loss_config:
      ball_num_samples: 20
      ball_radius: 0.3
      cvx_coeff_loss_type: quad_inv
      min_grad_density: 1.0e-06
      weight_diff_loss:
        cvx_coeff_loss: 1
        density_set_one: 0.0001
        density_value: 0.001
        gradient_loss: 1.0e-05
        local_convex_loss: 1
      weight_min_grad_density: 1000.0
  loss_reg:
    default_mean: 0
    default_scale: 0
    specials:
      actuator_forces:
        mean: 0.0
        scale: 1
      coriolis_forces:
        mean: 0.0
        scale: 1
      gravity_forces:
        mean: 0.0
        scale: 1
      position_correction:
        mean: 0.0
        scale: 1
      residual_forces:
        mean: 0.0
        scale: 1
  loss_traj_train:
    discount_factor: 0.9
    likehood:
      discount_factor: 0.9
      nll_type: gauss_approx
      noise_scale:
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
    num_substeps: 1
    sampling:
      action_sampling_strategy:
        default: first
      horizon_fit: 2
      integration_method: euler_maruyama
      num_samples: 1
      stepsize_range:
      - 1
      - 1
    validation_sampling:
      action_sampling_strategy:
        default: first
      horizon_test: 5
      stepsize_range:
      - 1
      - 1
  loss_weights:
    DataLoss: 1.0
    RegLoss: 0.0005
    VarBoundLoss: 1.0e-05
model:
  diffusion_term:
    args:
      _num_controls: 6
      _num_states: 19
      default_feature_values: []
      density_free_nn_params:
        activation_fn: swish
        initial_value_range: 0.001
        layers_archictecture: []
      density_nn_params:
        activation_fn: swish
        initial_value_range: 0.1
        layers_archictecture:
        - 64
        - 64
      diffusion_is_control_dependent: true
      feature_density_scaling:
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      - 1.0
      feature_parameters_to_use: []
      is_reward_in_state: true
      upper_bound_diffusion:
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0.1
      - 0
    model_name: BasicDistanceAwareDiffusionTerm
  drift_term:
    args:
      _mean_controls:
      - 0.10069654881954193
      - -0.06710564345121384
      - 0.07148189097642899
      - 0.3473506271839142
      - 0.32321324944496155
      - -0.033888280391693115
      _mean_states:
      - 151.77706909179688
      - -0.007915517315268517
      - 0.17710815370082855
      - 0.0602954663336277
      - -0.09376681596040726
      - 0.044774387031793594
      - 0.30794501304626465
      - 0.155332550406456
      - -0.019704671576619148
      - 5.990058422088623
      - -0.06069474294781685
      - -0.09029137343168259
      - 0.020285435020923615
      - -0.09871239960193634
      - 0.10874100774526596
      - 0.12155795097351074
      - 0.25895777344703674
      - 0.1730789989233017
      - 2838.351779875009
      _names_angles:
      - rooty
      - bthigh
      - bshin
      - bfoot
      - fthigh
      - fshin
      - ffoot
      _names_controls:
      - Cbthigh
      - Cbshin
      - Cbfoot
      - Cfthigh
      - Cfshin
      - Cffoot
      _names_positions:
      - rootx
      - rootz
      - rooty
      - bthigh
      - bshin
      - bfoot
      - fthigh
      - fshin
      - ffoot
      _names_states:
      - rootx
      - rootz
      - rooty
      - bthigh
      - bshin
      - bfoot
      - fthigh
      - fshin
      - ffoot
      - Vrootx
      - Vrootz
      - Arooty
      - Abthigh
      - Abshin
      - Abfoot
      - Afthigh
      - Afshin
      - Affoot
      - reward
      _scale_controls:
      - 0.9497740864753723
      - 0.8120582103729248
      - 0.7976172566413879
      - 0.7161867022514343
      - 0.7961147427558899
      - 0.8083996772766113
      _scale_states:
      - 90.78462982177734
      - 0.08130235970020294
      - 0.37443673610687256
      - 0.44862690567970276
      - 0.36217162013053894
      - 0.3375500440597534
      - 0.30208757519721985
      - 0.47498294711112976
      - 0.35051804780960083
      - 1.5014443397521973
      - 0.8458287119865417
      - 2.155139684677124
      - 11.407608032226562
      - 8.62087631225586
      - 9.032414436340332
      - 7.150745868682861
      - 12.440767288208008
      - 8.827804565429688
      - 1695.8462964512678
      actuator_forces_nn:
        args:
          activation_fn: swish
          initial_value_range: 0.001
          layers_archictecture:
          - 128
          - 128
          - 128
        features:
        - rootz
        - cos_angles
        - sin_angles
        - velocities
      coriolis_forces_nn:
        args:
          activation_fn: swish
          initial_value_range: 0.001
          layers_archictecture:
          - 128
          - 128
          - 128
        features:
        - rootz
        - cos_angles
        - sin_angles
        - velocities
      gravity_forces_nn: {}
      mass_matrix_nn: {}
      residual_forces_nn:
        args:
          activation_fn: swish
          initial_value_range: 0.001
          layers_archictecture:
          - 200
          - 200
          - 200
        features:
        - rootz
        - cos_angles
        - sin_angles
        - velocities
        - controls
      reward_nn:
        args:
          activation_fn: swish
          initial_value_range: 0.001
          layers_archictecture:
          - 64
          - 64
          - 64
        features:
        - positions
        - velocities
        - controls
    model_name: RBD_Drift
model_optimizer:
- name: scale_by_adam
- name: linear_schedule
  params:
    end_value: -0.001
    init_value: -0.01
    transition_steps: 100000
  scheduler: true
model_training:
  dad_batch_size: 128
  early_stopping_epochs: 300
  freq_update_dad: 1
  num_gradient_steps: 400
  save_freq: 4000
  test_batch: 128
  test_freq: 2000
  test_num_steps: 80
  train_batch: 128
seed: 100
track_n_checkpoints:
  async_exec: false
  max_to_keep: 5
  metrics:
    Test/StateLoss: 5.0
    Train/StateLoss: 1.0
