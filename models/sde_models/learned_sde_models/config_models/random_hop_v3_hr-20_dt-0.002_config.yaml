data_dir: hopper-random-v2
model:
  actuator_forces:
    activation_fn: tanh
    hidden_layers:
    - 32
    - 32
  control_dependent_noise: false
  coriolis_matrix:
    activation_fn: tanh
    hidden_layers:
    - 32
    - 32
  data_state_scaling: true
  diffusion_density_nn:
    density_nn:
      activation_fn: swish
      hidden_layers:
      - 32
      - 32
      init_value: 0.01
    indx_noise_in:
    - 0
    - 1
    - 5
    - 6
    - 7
    indx_noise_out:
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    scaler_nn:
      init_value: 0.01
      type: scaler
  gravity:
    activation_fn: tanh
    hidden_layers:
    - 32
    - 32
  horizon: 1
  n_u: 3
  n_x: 11
  n_y: 11
  noise_prior_params:
  - 0.01
  - 0.01
  - 0.01
  - 0.01
  - 0.01
  - 0.1
  - 0.1
  - 0.1
  - 0.1
  - 0.1
  - 0.1
  num_particles: 1
  num_substeps: 4
  residual_forces:
    activation_fn: tanh
    hidden_layers:
    - 64
    - 64
  sde_solver: simpletic_euler_maruyama
  state_scaling:
  - 1.3532897233963013
  - 0.19999995827674866
  - 1.357933759689331
  - 2.1054952144622803
  - 0.8601488471031189
  - 2.8590662479400635
  - 2.585909843444824
  - 8.406386375427246
  - 9.823725700378418
  - 10.0
  - 10.0
  stepsize: 0.05
output_file: random_hop_v3
ratio_seed: 10
ratio_test: 0.1
remove_test_data: true
sde_loss:
  data_stepsize: 0.008
  default_weights: 1.0
  density_loss:
    ball_nsamples: 20
    ball_radius: 0.1
    learn_mucoeff:
      type: constant
    mu_coeff: 10.0
  discount_pred: 0.1
  horizon: 5
  num_particles: 1
  obs_weights:
  - 0.13532897233963012
  - 0.019999995827674866
  - 1.357933759689331
  - 2.1054952144622803
  - 0.8601488471031189
  - 0.28590662479400636
  - 2.585909843444824
  - 0.8406386375427246
  - 9.823725700378418
  - 10.0
  - 10.0
  pen_data: 100.0
  pen_density_scvex: 1.0
  pen_grad_density: 0.1
  pen_scvex_mult: 1.0
  pen_weights: 1.0e-10
  seed: 25
  special_parameters_pen:
    density: 0
    scaler: 0
  stepsize: 0.008
  updated_obs_weights:
    0: 0.1
    1: 0.1
    5: 0.1
    7: 0.1
  warmup_diffusion: 10
sde_optimizer:
- name: scale_by_adam
- name: linear_schedule
  params:
    end_value: -0.001
    init_value: -0.01
    transition_steps: 100000
  scheduler: true
sde_training:
  TestStopingCrit:
    totalLoss: 1
  TrainStopingCrit:
    LossUnc: 0.1
    totalLoss: 1.0
  nepochs: 200
  num_test_eval_per_epoch: 10
  patience: 20
  test_batch: 512
  train_batch: 512
