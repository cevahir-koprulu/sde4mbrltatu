import matplotlib.pyplot as plt
import numpy as np
import os
import argparse
from training_info_dict import TRAINING_INFO_DICT
from matplotlib.patches import Patch

def parse_results_file(filepath):
    progress_f = os.path.join(filepath, "fake_eval_full=False.txt")
    with open(progress_f, 'r') as f:
        lines = f.readlines()
    pess, gt = [], []
    for line in lines:
        if "fake_best_eval_mean:" in line:
            pess = float(line.split(" ")[1])
        elif "fake_best_eval_mean_unpen:" in line:
            gt = float(line.split(" ")[1])
    return pess, gt

def get_results_dict(log_dir, tasks, models):
    results_dict = {}
    for task in tasks:
        results_dict[task] = {}
        models_dict = TRAINING_INFO_DICT[task]
        for model_name, model_dict in models_dict.items():
            if model_name not in models:
                continue
            results_dict[task][model_name] = {
                        "pess": [],
                        "gt": [],
                    }
            for seed, filename in model_dict["seeds"].items():
                file_path = os.path.join(log_dir, task, get_model_log_name(model_name), filename)
                pess, gt = parse_results_file(file_path)
                results_dict[task][model_name]["pess"].append(pess)
                results_dict[task][model_name]["gt"].append(gt)
            results_dict[task][model_name]["pess"] = np.array(results_dict[task][model_name]["pess"])
            results_dict[task][model_name]["gt"] = np.array(results_dict[task][model_name]["gt"])
    return results_dict

def plot_results(results_dict, fig_path, fontsize=28, figsize=(15, 6)):
    plt.rcParams['font.family'] = 'serif'
    plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']
    plt.rcParams['font.size'] = fontsize

    # Width of each bar group
    bar_width = 0.1
    colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']
    
    models = list(results_dict[list(results_dict.keys())[0]].keys())
    tasks = list(results_dict.keys())
    results_dict_reversed = {}
    for model in models:
        results_dict_reversed[model] = {}
        for task in results_dict.keys():
            results_dict_reversed[model][task] = results_dict[task][model]
    

    # Create the figure and axis
    fig, ax = plt.subplots(figsize=figsize, layout='constrained')
    num_tasks = len(tasks)
    num_models = len(models)
    x = np.arange(num_tasks)
    legend_elements = []
    for i, model in enumerate(models):
        if i==0:
            legend_elements.append(Patch(facecolor="none", edgecolor='black', hatch="", label="GT"))
            legend_elements.append(Patch(facecolor="none", edgecolor='black', hatch="//", label="Pess"))
        model_gt_mean = [results_dict_reversed[model][task]["gt"].mean() for task in tasks]
        model_gt_std = [results_dict_reversed[model][task]["gt"].std() for task in tasks]
        model_pess_mean = [results_dict_reversed[model][task]["pess"].mean() for task in tasks]
        model_pess_std = [results_dict_reversed[model][task]["pess"].std() for task in tasks]
        ax.bar(x + i * 2* bar_width, model_gt_mean, 
                color=colors[i], hatch="", capsize=5,
                edgecolor='black', width=bar_width, label=None, yerr=model_gt_std)
        ax.bar(x + (i * 2 + 1) * bar_width, model_pess_mean, 
            color=colors[i], hatch="//", capsize=5,
            edgecolor='black', width=bar_width, label=None, yerr=model_pess_std)
        legend_elements.append(Patch(facecolor=colors[i], label=get_model_label(model)))
    # ax.set_xlabel('Datasets')
    ax.set_ylabel('Human normalized score', fontsize=fontsize)
    # ax.set_yscale('log')
    ax.grid()
    ax.set_xticks(x + bar_width * (2 * num_models - 1) / 2)
    ax.set_xticklabels(tasks, fontsize=fontsize*0.75)
    ax.legend(handles=legend_elements, markerscale=4, loc='best', fontsize=fontsize*0.8)
    plt.savefig(f"{fig_path}.pdf", dpi=500)

def get_model_label(model):
    if model == "mopo":
        return "MOPO"
    elif model == "tatu_mopo_sde_rew":
        return r"$\mathregular{NUNO}^{\mathregular{R}}$"
    elif model == "tatu_mopo_sde":
        return "NUNO"
    elif model == "tatu_mopo":
        return "TATU+MOPO"
    else:
        return model
    
def get_model_log_name(model):
    if model == "mopo":
        return "tatu_mopo"
    elif model == "tatu_mopo_sde_rew":
        return "tatu_mopo_sde"
    else:
        return model

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--log-dir", type=str, default="log")
    parser.add_argument("--tasks", type=str, nargs="+", 
                        default=["halfcheetah-random-v2", "hopper-random-v2", "walker2d-random-v2"])
    parser.add_argument("--models", type=str, nargs="+", 
                        default=["tatu_mopo_sde_rew", "tatu_mopo_sde", "tatu_mopo", "mopo"])
    parser.add_argument("--fig-name-extra", type=str, default="")
    parser.add_argument("--save-dir", type=str, default="model_exploitation_results")
    args= parser.parse_args() 

    if not os.path.exists(args.save_dir):
        os.makedirs(args.save_dir)

    results = get_results_dict(args.log_dir, args.tasks, args.models)
    fig_path = os.path.join(args.save_dir, f"model_exploitation{args.fig_name_extra}")
    plot_results(results, fig_path)
